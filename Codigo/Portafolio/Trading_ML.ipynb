{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Trading_ML.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Ix3fTX_W_ku9DRU5hng1Z_SneqbYUsdT","authorship_tag":"ABX9TyNanjeroYk+jBKYMgQMfNyN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"V1cahvaLCiOH"},"source":["#Librerias\n","\n","Son las librerias necesarias para la ejecución del codigo, con el cual define la arquitectura de una red neuronal del tipo convolucional o multicapa, para la identificación de los momentos de inversión (alcista o bajista) de un portafolio de inversión."]},{"cell_type":"code","metadata":{"id":"TWskj34wCYdB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633449097049,"user_tz":300,"elapsed":30717,"user":{"displayName":"Pruebas IA","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12555408758403199651"}},"outputId":"535685d9-8955-4de6-ccd9-62d95cbda364"},"source":["#Ejecutar pip en la primera ejecución\n","#!pip install yahoo-fin --upgrade\n","#!pip install requests_html\n","\n","from yahoo_fin import stock_info\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import datetime as dt\n","import random\n","import os, signal\n","import tensorflow as tf\n","from keras.layers import Dense,Dropout,Conv1D,Input,Flatten,MaxPooling1D\n","from keras.models import Sequential,load_model\n","from keras.optimizers import adam_v2\n","from sklearn.metrics import accuracy_score\n","%run '/content/drive/MyDrive/Escrito/Codigo/Portafolio/Datos.ipynb' import *\n","%run '/content/drive/MyDrive/Escrito/Codigo/Portafolio/Portafolio.ipynb' import *"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting yahoo-fin\n","  Downloading yahoo_fin-0.8.9.1-py3-none-any.whl (10 kB)\n","Collecting requests-html\n","  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n","Collecting feedparser\n","  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from yahoo-fin) (1.1.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yahoo-fin) (2.23.0)\n","Collecting sgmllib3k\n","  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo-fin) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo-fin) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo-fin) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->yahoo-fin) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo-fin) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo-fin) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo-fin) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo-fin) (2021.5.30)\n","Collecting w3lib\n","  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n","Collecting pyquery\n","  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n","Collecting fake-useragent\n","  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n","Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo-fin) (0.0.1)\n","Collecting pyppeteer>=0.0.14\n","  Downloading pyppeteer-0.2.6-py3-none-any.whl (83 kB)\n","\u001b[K     |████████████████████████████████| 83 kB 1.9 MB/s \n","\u001b[?25hCollecting parse\n","  Downloading parse-1.19.0.tar.gz (30 kB)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 18.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo-fin) (4.8.1)\n","Collecting websockets<10.0,>=9.1\n","  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n","\u001b[K     |████████████████████████████████| 103 kB 34.1 MB/s \n","\u001b[?25hCollecting pyee<9.0.0,>=8.1.0\n","  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo-fin) (1.4.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo-fin) (4.62.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo-fin) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo-fin) (3.5.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html->yahoo-fin) (4.6.3)\n","Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html->yahoo-fin) (4.2.6)\n","Collecting cssselect>0.7.9\n","  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n","Building wheels for collected packages: fake-useragent, parse, sgmllib3k\n","  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=3fef69a8608f65183708abc0a979a9549194d1184b23666a983518b98ee86150\n","  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n","  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=d7a11d7481aa03abae3f123fee26c90188fa953592cb438930bf10e2304dba12\n","  Stored in directory: /root/.cache/pip/wheels/9c/aa/cc/f2228050ccb40f22144b073f15a2c84f11204f29fc0dce028e\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=d2a834fd6efd87581830a9e0f1a0fd07d2318f01e5007aae0e08cefa0fe15f31\n","  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n","Successfully built fake-useragent parse sgmllib3k\n","Installing collected packages: websockets, urllib3, pyee, cssselect, w3lib, sgmllib3k, pyquery, pyppeteer, parse, fake-useragent, requests-html, feedparser, yahoo-fin\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed cssselect-1.1.0 fake-useragent-0.1.11 feedparser-6.0.8 parse-1.19.0 pyee-8.2.2 pyppeteer-0.2.6 pyquery-1.4.3 requests-html-0.10.0 sgmllib3k-1.0.0 urllib3-1.25.11 w3lib-1.22.0 websockets-9.1 yahoo-fin-0.8.9.1\n","Requirement already satisfied: requests_html in /usr/local/lib/python3.7/dist-packages (0.10.0)\n","Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from requests_html) (0.1.11)\n","Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from requests_html) (0.2.6)\n","Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests_html) (0.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from requests_html) (2.23.0)\n","Requirement already satisfied: pyquery in /usr/local/lib/python3.7/dist-packages (from requests_html) (1.4.3)\n","Requirement already satisfied: parse in /usr/local/lib/python3.7/dist-packages (from requests_html) (1.19.0)\n","Requirement already satisfied: w3lib in /usr/local/lib/python3.7/dist-packages (from requests_html) (1.22.0)\n","Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.8.1)\n","Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.25.11)\n","Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.62.3)\n","Requirement already satisfied: websockets<10.0,>=9.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (9.1)\n","Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (8.2.2)\n","Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.7.4.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests_html) (4.6.3)\n","Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests_html) (1.1.0)\n","Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests_html) (4.2.6)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (2.10)\n","Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from w3lib->requests_html) (1.15.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"bCUCyx8czyfy"},"source":["#Variables de iniciales\n","\n","\n","Lista de las emisoras a extraer información, así como las fechas iniciales y finales de la información requerida"]},{"cell_type":"code","metadata":{"id":"ud8Z6_Crz5zs"},"source":["fecha_inicio='2020-01-01'\n","fecha_final=\"2021-05-30\"\n","\n","#Carga empresas a evaluar\n","emp= pd.read_csv('/content/drive/MyDrive/Escrito/Codigo/Portafolio/Emisoras.csv',encoding='latin-1')   #Actualizar Ruta del archivo\n","emp.head()\n","\n","#Definición de emisoras \n","lista_emp= np.array(emp['Emisora'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aTC0fzmV0uy-"},"source":["#Red Neuronal\n","\n","Definición de la arquitectura de una red neuronal la cual puede ser Multicapa o Convolucional\n"," "]},{"cell_type":"code","metadata":{"id":"MxxIElpZ04cO"},"source":["#Definición de las semillas del modelo\n","def set_seeds(seed=1000):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  tf.random.set_seed(seed)\n","\n","#Creación de la Red Neuronal Multicapa\n","def RNN(entrada=10,capas=1, neuronas=[128], optimizer='Adam',dropout=False,td=0.1):\n","  red = Sequential()\n","  red.add(Dense(neuronas[0], input_dim=entrada,activation='relu'))\n","  for c in range(capas):\n","    if dropout:\n","      red.add(Dropout(td))\n","    red.add(Dense(neuronas[c], activation='relu'))\n","  red.add(Dense(1, activation='sigmoid'))\n","  red.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n","  return red\n","\n","#Creación de la Red Neuronal Convolucional\n","def CNN(entrada=10,capas=1, neuronas=[128], optimizer='Adam',dropout=False,td=0.1):\n","  red=Sequential()\n","  red.add(Conv1D(neuronas[0], activation='relu',kernel_size=1,input_shape=[entrada,1]))\n","  red.add(MaxPooling1D())\n","  for c in range(capas):\n","    if dropout:\n","      red.add(Dropout(td))\n","    red.add(Conv1D(neuronas[c], activation='relu',kernel_size=1))\n","    red.add(MaxPooling1D())\n","  red.add(Flatten())\n","  red.add(Dense(1, activation='sigmoid'))\n","  red.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'],)\n","  return red"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nOJvMhoc2GUL"},"source":["#Implementación del modelo \n","\n","Funciones para la implementación de una red neuronal para la identificación de momentos del mercado y tomar la decisión de inversión"]},{"cell_type":"code","metadata":{"id":"OV3Bc3vHq6Qb"},"source":["#Implementación de red MLP para identificar el movimiento del portafolio en el mercado\n","def decision_MLP(path,emisoras,pesos,fecha_inicio,fecha_final):\n","  datos=datos1_port(path,emisoras,pesos,fecha_inicio,fecha_final)\n","  datos1=datos.copy()\n","  datos1=datos_ML1(datos1,3)\n","  x1=list(datos1.columns)\n","  print(datos1)\n","  y1=['clase']\n","  x1.remove('clase')\n","  x1.remove('clase2')\n","  x1.remove('open')\n","  x1.remove('low')\n","  x1.remove('high')\n","  x1.remove('volume')\n","  x1.sort()\n","  red=RNN(len(x1),1,[64],dropout=True,td=0.05)\n","  acc=-float('inf')\n","  for i in range(1000):\n","    modelo=red.fit(datos1[x1],datos1[y1],epochs=1)\n","    if modelo.history['accuracy'][0]>acc:\n","      red.save('decision.h5')\n","      acc=modelo.history['accuracy'][0]\n","      print ('Modelo Actualizado Guardado..')\n","  return datos1,x1,y1\n","\n","#Implementación de red MLP para predecir el movimiento del mercado\n","def decision_CNN(path,emisoras,pesos,fecha_inicio,fecha_final):\n","  datos=datos1_port(path,emisoras,pesos,fecha_inicio,fecha_final)\n","  datos1=datos.copy()\n","  datos1=datos_ML1(datos1,3)\n","  x1=list(datos1.columns)\n","  y1=['clase']\n","  x1.remove('clase')\n","  x1.remove('clase2')\n","  x1.remove('open')\n","  x1.remove('low')\n","  x1.remove('high')\n","  x1.remove('volume')\n","  x1.sort()\n","  red=CNN(len(x1),1,[64],dropout=True,td=0.05)\n","  acc=-float('inf')\n","  for i in range(1000):    \n","    dat_conv= datos1[x1].to_numpy()\n","    dat_conv=dat_conv.reshape((datos1[x1].shape[0],datos1[x1].shape[1],1))\n","    modelo=red.fit(dat_conv,datos1[y1],epochs=1,verbose=0)\n","    if modelo.history['accuracy'][0]>acc:\n","      red.save('decision_cnn.h5')\n","      acc=modelo.history['accuracy'][0]\n","  return datos1,x1,y1\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nh_7jXFF1Lq5"},"source":["#Evaluación del Modelo\n","\n","Función para la evaluación de la red neuronal implementada a partir de un conjunto de datos historicos."]},{"cell_type":"code","metadata":{"id":"BBQErqSr1OXY"},"source":["def eva_red(path,modelo,emisoras,pesos,fe_inicio,fe_fin):\n","  red=load_model(modelo)\n","  datos= datos1_eval(path,emisoras,pesos,fe_inicio,fe_fin+dt.timedelta(days=1))\n","  datos1=datos.copy()\n","  datos1=datos_ML1(datos1,3)\n","  n,m=datos1.shape\n","  y=['clase']\n","  x=list(datos1.columns)\n","  x.sort()\n","  dtest=datos1[-1:]\n","  dtest=datos1[-1:].to_numpy()\n","  dtest= dtest.reshape((1,m,1))\n","  predct=np.where(red.predict(dtest)>.5,1,0)\n","  return int(predct),datos['close'][datos.index[-1]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PP6Fwgw9hSBT"},"source":["#Evaluación de Red Neuronal Multicapa vs Red Neuronal Convolucional\n","\n","Función de evaluación y comparación de Accuracies obtenidos de cada una de las redes neuronales, y definir la mejor evaluada."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EubiDKprTdr4","outputId":"bc33d3e5-c3dd-4c92-ceec-c60c7419c563"},"source":["def comparativo(path,lista_emp,fecha_inicio,fecha_final,n=2,t=10):\n","  acc=[];acct=[]\n","  cacc=[];cacct=[]\n","  for _ in range(t):\n","    #n=2\n","    pesos=np.random.rand(n)\n","    pesos=pesos/sum(pesos)\n","    print(pesos)\n","    #pesos=[1/n]*n\n","    lista=np.random.choice(lista_emp,n)\n","    print(lista)\n","    datosm,xm,ym=decision_MLP(path,lista,pesos,fecha_inicio,fecha_final)\n","    datosc,xc,yc=decision_CNN(path,lista,pesos,fecha_inicio,fecha_final)\n","    red_final= load_model('decision.h5')\n","    cnn_final= load_model('decision_cnn.h5')\n","    pred=np.where(red_final.predict(datosm[xm])>.5,1,0)\n","    acc.append(np.sum(pred==datosm[ym])/datosm.shape[0])\n","    dtrain=datosc[xc].to_numpy()\n","    dtrain= dtrain.reshape((datosc[xc].shape[0],datosc[xc].shape[1],1))\n","    predc=np.where(cnn_final.predict(dtrain)>.5,1,0)\n","    cacc.append(np.sum(predc==datosc[yc])/datosc.shape[0])\n","    fecha_inicio_test='2021-03-01'\n","    fecha_final_test='2021-08-31'\n","    datos_test=datos1_port(path,lista,pesos,fecha_inicio_test,fecha_final_test)\n","    datos_test2=datos_test.copy()\n","    datos_test2=datos_ML1(datos_test2,3)\n","    predt=np.where(red_final.predict(datos_test2[xm])>.5,1,0)\n","    acct.append(np.sum(predt==datos_test2[ym])/datos_test2.shape[0])\n","    dtest=datos_test2[xc].to_numpy()\n","    dtest= dtest.reshape((datos_test2[xc].shape[0],datos_test2[xc].shape[1],1))\n","    predct=np.where(cnn_final.predict(dtest)>.5,1,0)\n","    cacct.append(np.sum(predct==datos_test2[yc])/datos_test2.shape[0])\n","    print('Red Multicapa')\n","    print('Training',sum(acc)/float(len(acc)),acc)  \n","    print('Test',sum(acct)/float(len(acct)),acct)  \n","    print('Red Convolucional')\n","    print('Training',sum(cacc)/float(len(cacc)),cacc)  \n","    print('Test',sum(cacct)/float(len(cacct)),cacct)  \n","  return acc,acct,cacc,cacct\n","    \n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.45977902 0.54022098]\n","['TERRA13.MX' 'WFC.MX']\n"]}]},{"cell_type":"markdown","metadata":{"id":"LllG-pjlhbhF"},"source":["#Evaluación de la Red Neuronal Convolucional"]},{"cell_type":"code","metadata":{"id":"zRoF9S1khZ23"},"source":["def conv():\n","  acc=[];acct=[]\n","  for _ in range(10):\n","    n=5\n","    pesos=[1/n]*n\n","    lista=np.random.choice(lista_emp,n)\n","    print(lista)\n","    datos,x,y=decision_CNN(lista,pesos,fecha_inicio,fecha_final)\n","    red_final= load_model('decision.h5')\n","    pred=np.where(red_final.predict(datos[x])>.5,1,0)\n","    acc.append(np.sum(pred==datos[y])/datos.shape[0])\n","    fecha_inicio_test='2021-03-01'\n","    fecha_final_test='2021-08-31'\n","    datos_test=datos_port(lista,pesos,fecha_inicio_test,fecha_final_test)\n","    datos_test2=datos_test.copy()\n","    datos_test2=datos_ML1(datos_test2,3)\n","    predt=np.where(red_final.predict(datos_test2[x])>.5,1,0)\n","    acct.append(np.sum(predt==datos_test2[y])/datos_test2.shape[0])\n","    print('Training',sum(acc)/float(len(acc)))  \n","    print('Test',sum(acct)/float(len(acct)))  \n"],"execution_count":null,"outputs":[]}]}